"""Functions related to the GNIMBUS method.

References:
"""  # noqa: RUF002

import numpy as np

from desdeo.problem import (PolarsEvaluator, Problem, VariableType, Variable,
                            objective_dict_to_numpy_array,
                            unflatten_variable_array,
                            )

from desdeo.tools import (
    BaseSolver,
    SolverOptions,
    SolverResults,
    add_group_asf_diff,
    add_group_asf,
    add_group_asf_agg,
    add_group_guess_sf_diff,
    add_group_guess,
    add_group_guess_agg,
    add_group_nimbus,
    add_group_stom,
    add_group_stom_agg,
    guess_best_solver,
    add_asf_diff,
    add_asf_nondiff,
    add_nimbus_sf_diff,
    add_nimbus_sf_nondiff,
)
from desdeo.mcdm.nimbus import (
    # generate_starting_point,
    solve_intermediate_solutions,
    infer_classifications,
    NimbusError
)
import polars as pl


def explain(problem, classifications, results: [SolverResults]):
    """
    # A placeholder for a function to explain how the found solutions correspond to the group's preferences; helper for the moderator.
    """
    pass

def majority_rule(votes: dict[str, int]):
    """
        TODO: move to some upcoming GDM tools folder
    """
    from collections import Counter

    counts = Counter(votes.values())
    all_votes = sum(counts.values())
    for vote, c in counts.items():
        if c > all_votes // 2:
            return vote
    return None

def plurality_rule(votes: dict[str, int]):
    """
        TODO: move to some upcoming GDM tools folder
    """
    from collections import Counter

    counts = Counter(votes.values())
    max_votes = max(counts.values())
    winners = [vote for vote, c in counts.items() if c == max_votes]

    return winners

def voting_procedure(problem: Problem, solutions, votes_idxs: dict[str, int]) -> SolverResults:
    """
        CLEAN THIS UP
        Works properly for 4 votes and 4 solutions as per design.
    """
    winner_idx = None

    # call majority
    winner_idx = majority_rule(votes_idxs)
    if winner_idx is not None:
        print("Majority winner", winner_idx)
        return solutions[winner_idx]

    # call plurality
    winners = plurality_rule(votes_idxs)
    print("winners")
    if len(winners) == 1:
        print("Plurality winner", winners[0])
        return solutions[winners[0]]  # need to unlist the winners list
    if len(winners) == 2:
        # if two same solutions with same number of votes, call intermediate
        # TODO: change this to dec vars when they exist
        # wsol1, wsol2 = solutions[winners[0]].optimal_variables, solutions[winners[1]].optimal_variables
        wsol1, wsol2 = solutions[winners[0]].optimal_objectives, solutions[winners[1]].optimal_objectives
        print("Finding intermediate solution between", wsol1, wsol2)
        # return solve_intermediate_solutions_only_objs(problem, wsol1, wsol2, num_desired=3)
        return solve_intermediate_solutions(problem, wsol1, wsol2, num_desired=1)[0]
    else:
        print("TIE-breaking, select first solution (group nimbus scalarization)")
        return solutions[0]  # need to unlist the winners list


def solve_intermediate_solutions_only_objs(  # noqa: PLR0913
    problem: Problem,
    solution_1: dict[str, VariableType],
    solution_2: dict[str, VariableType],
    num_desired: int,
    scalarization_options: dict | None = None,
    solver: BaseSolver | None = None,
    solver_options: SolverOptions | None = None,
) -> list[SolverResults]:
    """Generates a desired number of intermediate solutions between two given solutions.

    Generates a desires number of intermediate solutions given two Pareto optimal solutions.
    The solutions are generated by taking n number of steps between the two solutions in the
    objective space. The objective vectors corresponding to these solutions are then
    utilized as reference points in the achievement scalarizing function. Solving the functions
    for each reference point will project the reference point on the Pareto optimal
    front of the problem. These projected solutions are then returned. Note that the
    intermediate solutions are generated _between_ the two given solutions, this means the
    returned solutions will not include the original points.

    Args:
        problem (Problem): the problem being solved.
        solution_1 (dict[str, VariableType]): the first of the solutions between which the intermediate
            solutions are to be generated.
        solution_2 (dict[str, VariableType]): the second of the solutions between which the intermediate
            solutions are to be generated.
        num_desired (int): the number of desired intermediate solutions to be generated. Must be at least `1`.
        scalarization_options (dict | None, optional): optional kwargs passed to the scalarization function.
            Defaults to None.
        solver (BaseSolver | None, optional): solver used to solve the problem.
            If not given, an appropriate solver will be automatically determined based on the features of `problem`.
            Defaults to None.
        solver_options (SolverOptions | None, optional): optional options passed
            to the `solver`. Ignored if `solver` is `None`.
            Defaults to None.

    Returns:
        list[SolverResults]: a list with the projected intermediate solutions as
            `SolverResults` objects.
    """

    if int(num_desired) < 1:
        msg = f"The given number of desired intermediate ({num_desired=}) solutions must be at least 1."
        raise NimbusError(msg)

    init_solver = guess_best_solver(problem) if solver is None else solver
    _solver_options = None if solver_options is None or solver is None else solver_options

    # compute the element-wise difference between each solution (in the decision space)
    solution_1_arr = objective_dict_to_numpy_array(problem, solution_1)
    solution_2_arr = objective_dict_to_numpy_array(problem, solution_2)
    delta = solution_1_arr - solution_2_arr

    # the '2' is in the denominator because we want to calculate the steps
    # between the two given points; we are not interested in the given points themselves.
    step_size = delta / (2 + num_desired)

    intermediate_points = np.array([solution_2_arr + i * step_size for i in range(1, num_desired + 1)])

    intermediate_var_values = pl.DataFrame(
        [unflatten_variable_array(problem, x) for x in intermediate_points],
        schema=[
            (var.symbol, pl.Float64 if isinstance(var, Variable) else pl.Array(pl.Float64, tuple(var.shape)))
            for var in problem.variables
        ],
    )

    # evaluate the intermediate points to get reference points
    # TODO(gialmisi): an evaluator might have to be selected depending on the problem
    evaluator = PolarsEvaluator(problem)

    print("intermediate points:", intermediate_points)
    print("==")
    reference_points = (
        evaluator.evaluate(intermediate_var_values).select([obj.symbol for obj in problem.objectives]).to_dicts()
    )

    print("==")
    print("intermediate rps:", reference_points)
    # for each reference point, add and solve the ASF scalarization problem
    # projecting the reference point onto the Pareto optimal front of the problem.
    # TODO(gialmisi): this can be done in parallel.
    intermediate_solutions = []
    for rp in reference_points:
        # add scalarization
        add_asf = add_asf_diff if problem.is_twice_differentiable else add_asf_nondiff
        asf_problem, target = add_asf(problem, "target", rp, **(scalarization_options or {}))

        solver = init_solver(asf_problem, _solver_options)

        # solve and store results
        result: SolverResults = solver.solve(target)

        intermediate_solutions.append(result)

    return intermediate_solutions

def dict_of_rps_to_list_of_rps(reference_points: dict[str, dict[str, float]]) -> list[dict[str, float]]:
    """
    Convert dict containing the DM key to an ordered list.
    """
    return list(reference_points.values())

def list_of_rps_to_dict_of_rps(reference_points: list[dict[str, float]]) -> dict[str, dict[str, float]]:
    """
    Convert the ordered list to a dict contain the DM keys. TODO: Later maybe get these keys from somewhere.
    """
    return {f"DM{i+1}": rp for i, rp in enumerate(reference_points)}


def infer_ordinal_classifications(
    problem: Problem, current_objectives: dict[str, float], reference_points: dict[str, dict[str, float]]
) -> dict[str, tuple[str, float | None]]:
    """
    TODO: improve, currently only works proprely if DMs RPS are either near nadir, ideal or the current iteration point.
    Returns lists for each DM containing value for each objective function with integers 0,1,2 for impair, keep the same and improve respectively.
    """

    if None in problem.get_ideal_point() or None in problem.get_nadir_point():
        msg = "The given problem must have both an ideal and nadir point defined."
        raise NimbusError(msg)

    """ TODO:
    if not all(obj.symbol in reference_point for obj in problem.objectives):
        msg = f"The reference point {reference_point} is missing entries " "for one or more of the objective functions."
        raise NimbusError(msg)
    """
    if not all(obj.symbol in current_objectives for obj in problem.objectives):
        msg = (
            f"The current point {current_objectives} is missing entries " "for one or more of the objective functions."
        )
        raise NimbusError(msg)

    # derive the classifications based on the reference point and and previous
    # objective function values
    # example = np.array([[2, 0, 1, 2], [1, 0, 2, 1], [2, 1, 0, 1]])
    classifications = []
    print(current_objectives)

    for rp in reference_points:
        class_for_dm = []
        for obj in problem.objectives:
            if np.isclose(reference_points[rp][obj.symbol], obj.nadir, atol=0.1):
                # the objective is free to change
                class_for_dm.append(0)
            elif np.isclose(reference_points[rp][obj.symbol], obj.ideal, atol=0.1):
                # the objective should improve
                class_for_dm.append(2)
            elif np.isclose(reference_points[rp][obj.symbol], current_objectives[obj.symbol], atol=0.1):
                # the objective should stay as it is
                class_for_dm.append(1)
            else:
                v = None
                if current_objectives[obj.symbol] < reference_points[rp][obj.symbol] < obj.nadir:
                    print(reference_points[rp][obj.symbol])
                    v = 2
                elif current_objectives[obj.symbol] > reference_points[rp][obj.symbol] > obj.ideal:
                    print(reference_points[rp][obj.symbol])
                    v = 0
                class_for_dm.append(v)

        classifications.append(class_for_dm)
        # classifications |= classification

    print("CLASSES", classifications)
    return np.array(classifications)


def convert_to_nimbus_classification(problem: Problem, compromise_classification: list[int]) -> dict[str, tuple[str, float | None]]:
    r""" Converts compromise classification for the group to the NIMBUS classification format.
    """
    classifications = {}
    for i in range(len(compromise_classification)):
        if compromise_classification[i] == 0:
            # the objective is free to change
            classification = {problem.objectives[i].symbol: ("0", None)}
        elif compromise_classification[i] == 1:
            # the objective should stay as it is
            classification = {problem.objectives[i].symbol: ("=", None)}
        elif compromise_classification[i] == 2:
            # the objective should improve
            classification = {problem.objectives[i].symbol: ("<", None)}
        # else:
        #    msg = f"Warning: GNIMBUS could not figure out the classification for objective {problem.objectives[i].symbol}."
        #    raise NimbusError(msg)

        classifications |= classification
    return classifications

# TODO: make better!
def find_min_max_values(po_list, problem):
    max_values = {}
    min_values = {}
    for obj in problem.objectives:
        obj = obj.symbol
        values = [s[obj] for s in po_list]
        max_values[obj] = max(values)
        min_values[obj] = min(values)
    return max_values, min_values

# TODO: comments
def scale_delta(problem, d):
    delta = {}
    ideal = problem.get_ideal_point()
    nadir = problem.get_nadir_point()

    for obj in problem.objectives:
        delta.update({obj.name: d*(ideal[obj.name] - nadir[obj.name])})
    return delta


def solve_sub_problems(  # noqa: PLR0913
    problem: Problem,
    current_objectives: dict[str, float],
    reference_points: dict[str, dict[str, float]],
    num_desired: int,
    phase: str,
    scalarization_options: dict | None = None,
    create_solver: BaseSolver | None = None,
    solver_options: SolverOptions | None = None,
) -> list[SolverResults]:
    r"""Solves a desired number of sub-problems as defined in the NIMBUS methods.

    Solves 1-4 scalarized problems utilizing different scalarization
    functions. The scalarizations are based on the classification of a
    solutions provided by a decision maker. The classifications
    are represented by a reference point. Returns a number of new solutions
    corresponding to the number of scalarization functions solved.

    Depending on `num_desired`, solves the following scalarized problems corresponding
    the the following scalarization functions:

    1.  the NIMBUS scalarization function,
    2.  the STOM scalarization function,
    3.  the achievement scalarizing function, and
    4.  the GUESS scalarization function.

    Raises:
        NimbusError: the given problem has an undefined ideal or nadir point, or both.
        NimbusError: either the reference point of current objective functions value are
            missing entries for one or more of the objective functions defined in the problem.

    Args:
        problem (Problem): the problem being solved.
        current_objectives (dict[str, float]): an objective dictionary with the objective functions values
            the classifications have been given with respect to.
        reference_point (dict[str, float]): an objective dictionary with a reference point.
            The classifications utilized in the sub problems are derived from
            the reference point.
        num_desired (int): the number of desired solutions to be solved. Solves as
            many scalarized problems. The value must be in the range 1-4.
        scalarization_options (dict | None, optional): optional kwargs passed to the scalarization function.
            Defaults to None.
        create_solver (CreateSolverType | None, optional): a function that given a problem, will return a solver.
            If not given, an appropriate solver will be automatically determined based on the features of `problem`.
            Defaults to None.
        solver_options (SolverOptions | None, optional): optional options passed
            to the `create_solver` routine. Ignored if `create_solver` is `None`.
            Defaults to None.

    Returns:
        list[SolverResults]: a list of `SolverResults` objects. Contains as many elements
            as defined in `num_desired`.
    """
    if None in problem.get_ideal_point() or None in problem.get_nadir_point():
        msg = "The given problem must have both an ideal and nadir point defined."
        raise NimbusError(msg)

    # TODO: update these tests for multiple RPs

    """
    for reference_point in reference_points:
        if not all(obj.symbol in reference_point for obj in problem.objectives):
            msg = f"The reference point {reference_point} is missing entries " "for one or more of the objective functions."
            raise NimbusError(msg)

        if not all(obj.symbol in current_objectives for obj in problem.objectives):
            msg = f"The current point {reference_point} is missing entries " "for one or more of the objective functions."
            raise NimbusError(msg)

    """

    init_solver = create_solver if create_solver is not None else guess_best_solver(problem)
    _solver_options = solver_options if solver_options is not None else None

    print("CURRENT SOLVER", init_solver)

    solutions = []
    classification_list = []
    achievable_prefs = []

    ind_sols = []
    reference_points_list = dict_of_rps_to_list_of_rps(reference_points)

    # Solve for individual solutions
    for dm_rp in reference_points:
        classification = infer_classifications(problem, current_objectives, reference_points[dm_rp])
        nimbus_scala = add_nimbus_sf_diff if problem.is_twice_differentiable else add_nimbus_sf_nondiff  # non-diff gnimbus
        add_nimbus_sf = nimbus_scala

        problem_i_nimbus, nimbus_target = add_nimbus_sf(
            problem, "nimbus_sf", classification, current_objectives, **(scalarization_options or {})
        )

        if _solver_options:
            nimbus_solver = init_solver(problem_i_nimbus, _solver_options)
        else:
            nimbus_solver = init_solver(problem_i_nimbus)

        ind_sols.append(nimbus_solver.solve(nimbus_target))

    achievable_prefs = []
    for q in range(len(reference_points)):
        achievable_prefs.append(ind_sols[q].optimal_objectives)

    agg_aspirations, agg_bounds = find_min_max_values(achievable_prefs, problem)
    delta = scale_delta(problem, d=1e-8)

    if phase == "decision":
        for dm_rp in reference_points:
            # print("RPS", reference_points[dm_rp])
            classification_list.append(infer_classifications(problem, current_objectives, reference_points[dm_rp]))
        gnimbus_scala = add_group_nimbus_diff if problem.is_twice_differentiable else add_group_nimbus  # non-diff gnimbus
        add_nimbus_sf = gnimbus_scala

        problem_g_nimbus, gnimbus_target = add_nimbus_sf(
            problem, "nimbus_sf", classification_list, delta, agg_bounds, current_objectives, **(scalarization_options or {})
        )

        if _solver_options:
            gnimbus_solver = init_solver(problem_g_nimbus, _solver_options)  # type:ignore
        else:
            gnimbus_solver = init_solver(problem_g_nimbus)  # type:ignore

        solutions.append(gnimbus_solver.solve(gnimbus_target))

        return solutions

    elif phase == "learning":
        reference_points_list = dict_of_rps_to_list_of_rps(reference_points)

        # Add individual solutions
        for i in range(len(ind_sols)):
            solutions.append(ind_sols[i])
        # for i in range(len(achievable_prefs)):
        #    solutions.append(achievable_prefs[i])
        #
        """ Group nimbus scalarization with delta and added hard_constraints  """
        classification_list = []
        for dm_rp in reference_points:
            classification_list.append(infer_classifications(problem, current_objectives, reference_points[dm_rp]))
        print(classification_list)
        gnimbus_scala = add_group_nimbus_diff if problem.is_twice_differentiable else add_group_nimbus  # non-diff gnimbus
        add_nimbus_sf = gnimbus_scala

        problem_w_nimbus, nimbus_target = add_nimbus_sf(
            problem, "nimbus_sf", classification_list, current_objectives, agg_bounds, delta, **(scalarization_options or {})
        )

        if _solver_options:
            nimbus_solver = init_solver(problem_w_nimbus, _solver_options)  # type:ignore
        else:
            nimbus_solver = init_solver(problem_w_nimbus)

        solutions.append(nimbus_solver.solve(nimbus_target))

        """ SOLVING Group Scals with scaled delta, original RPs and hard_constraints """
        # solve STOM
        add_stom_sf = add_group_stom_diff if problem.is_twice_differentiable else add_group_stom
        problem_w_stom, stom_target = add_stom_sf(problem, "stom_sf", reference_points_list, agg_bounds, delta, **(scalarization_options or {}))
        if _solver_options:
            stom_solver = init_solver(problem_w_stom, _solver_options)
        else:
            stom_solver = init_solver(problem_w_stom)

        solutions.append(stom_solver.solve(stom_target))

        # solve ASF
        add_asf = add_group_asf_diff if problem.is_twice_differentiable else add_group_asf
        problem_w_asf, asf_target = add_asf(problem, "asf", reference_points_list, agg_bounds, delta, **(scalarization_options or {}))
        if _solver_options:
            asf_solver = init_solver(problem_w_asf, _solver_options)
        else:
            asf_solver = init_solver(problem_w_asf)

        solutions.append(asf_solver.solve(asf_target))

        # Solve GUESS
        add_guess_sf = add_group_guess_sf_diff if problem.is_twice_differentiable else add_group_guess
        problem_w_guess, guess_target = add_guess_sf(
            problem, "guess_sf", reference_points_list, agg_bounds, delta, **(scalarization_options or {})
        )
        if _solver_options:
            guess_solver = init_solver(problem_w_guess, _solver_options)
        else:
            guess_solver = init_solver(problem_w_guess)

        solutions.append(guess_solver.solve(guess_target))

        return solutions

    # elif phase == "crp":  # phase crp
    else:  # phase is crp
        # Add individual solutions
        for i in range(len(ind_sols)):
            solutions.append(ind_sols[i])

        """ Group nimbus scalarization with delta and added hard_constraints  """
        classification_list = []
        for dm_rp in reference_points:
            print("RPS", reference_points[dm_rp])
            classification_list.append(infer_classifications(problem, current_objectives, reference_points[dm_rp]))
        print(classification_list)
        gnimbus_scala = add_group_nimbus_diff if problem.is_twice_differentiable else add_group_nimbus  # non-diff gnimbus
        add_nimbus_sf = gnimbus_scala

        problem_w_nimbus, nimbus_target = add_nimbus_sf(
            problem, "nimbus_sf", classification_list, current_objectives, agg_bounds, delta, **(scalarization_options or {})
        )

        if _solver_options:
            nimbus_solver = init_solver(problem_w_nimbus, _solver_options)  # type:ignore
        else:
            nimbus_solver = init_solver(problem_w_nimbus)

        solutions.append(nimbus_solver.solve(nimbus_target))

        """ SOLVING Group Scals with scaled delta, agg. aspirations and hard_constraints """

        add_stom_sf2 = add_group_stom_agg
        # add_group_stom_sf_diff if problem.is_twice_differentiable else add_group_stom_sf

        problem_g_stom, stomg_target = add_stom_sf2(problem, "stom_sf2", agg_aspirations, agg_bounds, delta, **(scalarization_options or {}))
        if _solver_options:
            stomg_solver = init_solver(problem_g_stom, _solver_options)
        else:
            stomg_solver = init_solver(problem_g_stom)

        solutions.append(stomg_solver.solve(stomg_target))

        add_asf2 = add_group_asf_agg
        problem_g_asf, asfg_target = add_asf2(problem, "asf2", agg_aspirations, agg_bounds, delta, **(scalarization_options or {}))
        if _solver_options:
            asfg_solver = init_solver(problem_g_asf, _solver_options)
        else:
            asfg_solver = init_solver(problem_g_asf)

        solutions.append(asfg_solver.solve(asfg_target))

        add_guess_sf2 = add_group_guess_agg
        # add_group_guess_sf_diff if problem.is_twice_differentiable else add_group_guess_sf

        problem_g_guess, guess2_target = add_guess_sf2(
            problem, "guess_sf", agg_aspirations, agg_bounds, delta, **(scalarization_options or {})
        )

        if _solver_options:
            guess2_solver = init_solver(problem_g_guess, _solver_options)
        else:
            guess2_solver = init_solver(problem_g_guess)

        solutions.append(guess2_solver.solve(guess2_target))

        return solutions
